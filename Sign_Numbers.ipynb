{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(C,Y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    C: number of classes\n",
    "    Y: 2D label vector specifying the class of respective training example\n",
    "\n",
    "    Output:\n",
    "    2D one hot encoding \n",
    "    \"\"\"\n",
    "    return np.eye(C)[Y.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = h5py.File(\"./content/drive/MyDrive/signDataset/train_signs.h5\")\n",
    "dataset_test = h5py.File(\"./content/drive/MyDrive/signDataset/test_signs.h5\")\n",
    "\n",
    "#exploring the dataset\n",
    "print(\"keys: \", dataset_train.keys())\n",
    "print(dataset_train['list_classes'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig = np.array(dataset_train[\"train_set_x\"])\n",
    "y_train_orig = np.array(dataset_train[\"train_set_y\"])\n",
    "X_test_orig = np.array(dataset_test[\"test_set_x\"])\n",
    "y_test_orig = np.array(dataset_test[\"test_set_y\"])\n",
    "\n",
    "print(\"shapes: \", X_train_orig.shape, y_train_orig.shape, X_test_orig.shape, y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing inputs\n",
    "\n",
    "#briging y to the desired output shape, a column vector\n",
    "Y_train = y_train_orig.reshape((y_train_orig.shape[0],1))\n",
    "Y_test = y_test_orig.reshape((y_test_orig.shape[0],1))\n",
    "print(\"new shape: \", Y_train.shape, Y_test.shape)\n",
    "\n",
    "\n",
    "#normalising the rgb images\n",
    "X_train = X_train_orig/255\n",
    "X_test = X_test_orig/255\n",
    "\n",
    "#since y has multiple labels, we shall use one hot encoding\n",
    "Y_train = one_hot_encoding(6,Y_train)\n",
    "Y_test = one_hot_encoding(6,Y_test)\n",
    "print(\"new shape: \", Y_train.shape, Y_test.shape)\n",
    "#previously Y was stored as 0,1,2...5, now it is stored as a vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising the input\n",
    "index = 108\n",
    "print(\"y = \", Y_train[index])\n",
    "plt.imshow(X_train[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signModel(input_shape):\n",
    "    \"\"\"original\"\"\"\n",
    "    input_img = tf.keras.Input(input_shape)\n",
    "    Z1 = tfl.Conv2D(filters=8, kernel_size=(4,4), strides=(1,1), padding=\"same\")(input_img)\n",
    "    A1 = tfl.ReLU()(Z1)\n",
    "    P1 = tfl.MaxPooling2D(pool_size=(8,8), strides=(8,8), padding=\"same\")(A1)\n",
    "    Z2 = tfl.Conv2D(filters=16, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")(P1)\n",
    "    A2 = tfl.ReLU()(Z2)\n",
    "    P2 = tfl.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding=\"same\")(A2)\n",
    "    F = tfl.Flatten()(P2)\n",
    "    outputs = tfl.Dense(units=6, activation=\"softmax\")(F)\n",
    "    model = tf.keras.Model(inputs=input_img, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model = signModel((64,64,3))\n",
    "sign_model.compile(optimizer='adam',  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "sign_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sign_model.fit(X_train, Y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has high bias and variance, let us introduce batch normalisation and see what happens, it should facilitate training and decrease bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signModel2(input_shape):\n",
    "    \"\"\"original + BN\"\"\"\n",
    "    input_img = tf.keras.Input(input_shape)\n",
    "    Z1 = tfl.Conv2D(filters=8, kernel_size=(4,4), strides=(1,1), padding=\"same\")(input_img)\n",
    "    B1 = tfl.BatchNormalization(axis=3)(Z1)\n",
    "    A1 = tfl.ReLU()(B1)\n",
    "    P1 = tfl.MaxPooling2D(pool_size=(8,8), strides=(8,8), padding=\"same\")(A1)\n",
    "    Z2 = tfl.Conv2D(filters=16, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")(P1)\n",
    "    B2 = tfl.BatchNormalization(axis=3)(Z2)\n",
    "    A2 = tfl.ReLU()(B2)\n",
    "    P2 = tfl.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding=\"same\")(A2)\n",
    "    F = tfl.Flatten()(P2)\n",
    "    outputs = tfl.Dense(units=6, activation=\"softmax\")(F)\n",
    "    model = tf.keras.Model(inputs=input_img, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model2 = signModel2((64,64,3))\n",
    "sign_model2.compile(optimizer='adam',  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "sign_model2.fit(X_train, Y_train, epochs=100, batch_size=64)\n",
    "sign_model2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has high variance, let us introduce regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signModel3(input_shape):\n",
    "    \"\"\"original + BN\"\"\"\n",
    "    input_img = tf.keras.Input(input_shape)\n",
    "    drate = 0.3\n",
    "    Z1 = tfl.Conv2D(filters=8, kernel_size=(4,4), strides=(1,1), padding=\"same\")(input_img)\n",
    "    B1 = tfl.BatchNormalization(axis=3)(Z1)\n",
    "    A1 = tfl.ReLU()(B1)\n",
    "    P1 = tfl.MaxPooling2D(pool_size=(8,8), strides=(8,8), padding=\"same\")(A1)\n",
    "    Z2 = tfl.Conv2D(filters=16, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")(P1)\n",
    "    B2 = tfl.BatchNormalization(axis=3)(Z2)\n",
    "    A2 = tfl.ReLU()(B2)\n",
    "    F = tfl.Flatten()(A2)\n",
    "    outputs = tfl.Dense(units=6, activation=\"softmax\")(F)\n",
    "    model = tf.keras.Model(inputs=input_img, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model3 = signModel3((64,64,3))\n",
    "sign_model3.compile(optimizer='adam',  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "sign_model3.fit(X_train, Y_train, batch_size=32,epochs=25)\n",
    "sign_model3.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained model, 'X_test' is your test data, and 'Y_test' are the true labels\n",
    "# Assuming 'predictions' is your array of predicted probabilities\n",
    "predictions = sign_model3.predict(X_test)\n",
    "\n",
    "# Convert probabilities to one-hot encoded labels\n",
    "one_hot_predictions = np.eye(predictions.shape[1])[np.argmax(predictions, axis=1)]\n",
    "\n",
    "# Find the indices of the incorrect predictions\n",
    "incorrects = np.where(~np.all(one_hot_predictions == Y_test, axis=1))[0]\n",
    "\n",
    "# Print the indices of the incorrect predictions\n",
    "print(\"Indices of incorrect predictions: \", incorrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 20 incorrect indices\n",
    "first_20_incorrects = incorrects[:20]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(5, 5))\n",
    "\n",
    "for i, incorrect in enumerate(first_20_incorrects):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(X_test[incorrect], cmap='gray')\n",
    "    ax.set_title(f\"Predicted: {np.argmax(one_hot_predictions[incorrect])}, Actual: {np.argmax(Y_test[incorrect])}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model3.save('model98.keras', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model4 = tf.keras.models.load_model('model98.keras')\n",
    "sign_model4.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
